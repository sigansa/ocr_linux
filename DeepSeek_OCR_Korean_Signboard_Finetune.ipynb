{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2829a201",
   "metadata": {},
   "source": [
    "# 🔥 한국어 간판 OCR 파인튜닝 가이드\n",
    "\n",
    "**DeepSeek-OCR 모델을 한국어 간판 이미지로 파인튜닝하는 완전 가이드**\n",
    "\n",
    "---\n",
    "\n",
    "## 📚 프로젝트 개요\n",
    "\n",
    "- **목표**: 한국어 간판 이미지를 정확하게 읽어내는 OCR 모델 만들기\n",
    "- **모델**: DeepSeek-OCR (3B 파라미터)\n",
    "- **데이터**: 138,149개 학습 이미지 + 17,272개 검증 이미지\n",
    "- **방법**: Unsloth + LoRA (메모리 효율적 학습)\n",
    "- **플랫폼**: Google Colab Pro (A100 GPU 권장)\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 전체 과정 요약\n",
    "\n",
    "### **STEP 1: 로컬 (WSL)에서 데이터 준비** ⬅️ 먼저 이것부터!\n",
    "```bash\n",
    "# 데이터 압축 (WSL 터미널에서 실행)\n",
    "cd /root/data/deepseek_ocr\n",
    "tar -czf korean_signboard_data.tar.gz train.jsonl val.jsonl filtered_train/images filtered_val/images\n",
    "```\n",
    "\n",
    "### **STEP 2: Google Drive에 업로드**\n",
    "- 생성된 `korean_signboard_data.tar.gz` 파일을 Google Drive에 업로드\n",
    "- 위치: `내 드라이브` (루트)에 바로 업로드\n",
    "\n",
    "### **STEP 3: Google Colab에서 학습** ⬅️ 이 노트북!\n",
    "- 이 노트북을 Google Colab에 업로드\n",
    "- **런타임 → 런타임 유형 변경 → A100 GPU 선택**\n",
    "- 셀을 순서대로 실행\n",
    "\n",
    "---\n",
    "\n",
    "## ⏱️ 예상 소요 시간 (A100 GPU)\n",
    "\n",
    "| 단계 | 예상 시간 |\n",
    "|------|----------|\n",
    "| 환경 설정 | 3-5분 |\n",
    "| 데이터 압축 해제 | 2-3분 |\n",
    "| 모델 로딩 | 1-2분 |\n",
    "| **전체 학습 (138K 샘플)** | **2-3시간** |\n",
    "| 평가 및 저장 | 5-10분 |\n",
    "\n",
    "💡 **Tip**: 처음에는 `max_steps=100`로 테스트 후 전체 학습 진행 권장\n",
    "\n",
    "---\n",
    "\n",
    "## ⚠️ 시작하기 전 체크리스트\n",
    "\n",
    "- [ ] WSL에서 데이터 압축 완료\n",
    "- [ ] Google Drive에 `korean_signboard_data.tar.gz` 업로드 완료\n",
    "- [ ] Google Colab Pro 가입 (A100 GPU 사용 위해)\n",
    "- [ ] 이 노트북을 Colab에 업로드\n",
    "- [ ] **런타임 유형을 A100 GPU로 변경**\n",
    "\n",
    "---\n",
    "\n",
    "## 🚀 지금부터 시작!\n",
    "\n",
    "아래 셀들을 **순서대로** 실행하세요. 각 셀은 자동으로 다음 단계를 준비합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8646db",
   "metadata": {},
   "source": [
    "## 1️⃣ 환경 설정 및 GPU 확인\n",
    "\n",
    "**✅ 여기서 확인할 것:**\n",
    "1. GPU가 A100인지 확인 (상단에 `Tesla A100-SXM4-40GB` 표시되어야 함)\n",
    "2. 메모리가 40GB 이상인지 확인\n",
    "\n",
    "**⚠️ 만약 A100이 아니라면:**\n",
    "- 상단 메뉴: **런타임 → 런타임 유형 변경 → A100 GPU** 선택 후 다시 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cde0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 확인\n",
    "print(\"🔍 GPU 정보 확인 중...\\n\")\n",
    "!nvidia-smi\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✅ A100 GPU가 보이면 정상입니다!\")\n",
    "print(\"⚠️  T4나 다른 GPU라면 런타임 유형을 A100으로 변경하세요\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Unsloth 설치\n",
    "print(\"\\n📦 Unsloth 및 필요한 라이브러리 설치 중... (3-5분 소요)\")\n",
    "!pip install -q \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "!pip install -q --no-deps \"trl<0.9.0\" peft accelerate bitsandbytes\n",
    "\n",
    "print(\"\\n✅ 설치 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c62770",
   "metadata": {},
   "source": [
    "## 2️⃣ Google Drive 마운트 및 데이터 다운로드\n",
    "\n",
    "**📋 사전 준비사항:**\n",
    "\n",
    "### 로컬 (WSL)에서 이미 완료했어야 할 것:\n",
    "```bash\n",
    "cd /root/data/deepseek_ocr\n",
    "tar -czf korean_signboard_data.tar.gz train.jsonl val.jsonl filtered_train/images filtered_val/images\n",
    "```\n",
    "\n",
    "### Google Drive에 업로드:\n",
    "- 생성된 `korean_signboard_data.tar.gz` 파일을 **내 드라이브 루트**에 업로드\n",
    "\n",
    "---\n",
    "\n",
    "**✅ 준비되었다면 아래 셀 실행:**\n",
    "- Google 계정 로그인 팝업이 뜹니다\n",
    "- 권한 허용을 클릭하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efc9da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "print(\"🔐 Google Drive 마운트 중...\")\n",
    "print(\"➡️  팝업창에서 Google 계정을 선택하고 권한을 허용하세요\\n\")\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"\\n✅ Drive 마운트 완료!\")\n",
    "\n",
    "# 현재 디스크 상태 확인\n",
    "print(\"\\n📊 압축 해제 전 디스크 상태:\")\n",
    "!df -h /content\n",
    "\n",
    "# 데이터 압축 해제\n",
    "print(\"\\n📦 데이터 압축 파일 확인 중...\")\n",
    "\n",
    "# 파일 경로 확인 (여러 가능한 위치 체크)\n",
    "possible_paths = [\n",
    "    \"/content/drive/MyDrive/korean_signboard_data.tar.gz\",\n",
    "    \"/content/drive/My Drive/korean_signboard_data.tar.gz\",\n",
    "]\n",
    "\n",
    "tar_file = None\n",
    "for path in possible_paths:\n",
    "    if os.path.exists(path):\n",
    "        tar_file = path\n",
    "        file_size = os.path.getsize(path) / (1024**3)\n",
    "        print(f\"✅ 파일 발견: {path}\")\n",
    "        print(f\"📏 파일 크기: {file_size:.2f}GB\")\n",
    "        break\n",
    "\n",
    "if tar_file is None:\n",
    "    print(\"❌ 데이터 파일을 찾을 수 없습니다!\")\n",
    "    print(\"\\n📍 파일 위치 확인:\")\n",
    "    !ls -lh /content/drive/MyDrive/ | head -20\n",
    "    print(\"\\n⚠️  korean_signboard_data.tar.gz 파일을 Google Drive 루트에 업로드했는지 확인하세요!\")\n",
    "else:\n",
    "    # 압축 해제\n",
    "    print(f\"\\n📂 데이터 압축 해제 시작...\")\n",
    "    print(f\"⏱️  예상 시간: 5-10분\")\n",
    "    print(f\"💡 압축 해제 완료 즉시 압축 파일을 삭제하면 용량 확보됩니다!\\n\")\n",
    "    \n",
    "    !mkdir -p /content/data\n",
    "    !tar -xzf \"{tar_file}\" -C /content/data/\n",
    "    \n",
    "    print(\"\\n✅ 압축 해제 완료!\")\n",
    "    \n",
    "    # 압축 해제 후 디스크 상태\n",
    "    print(\"\\n📊 압축 해제 후 디스크 상태:\")\n",
    "    !df -h /content\n",
    "    \n",
    "    print(\"\\n📊 데이터 확인:\")\n",
    "    !ls -lh /content/data/\n",
    "    \n",
    "    # 샘플 수 확인\n",
    "    import subprocess\n",
    "    try:\n",
    "        train_count = int(subprocess.check_output(\"wc -l /content/data/train.jsonl\", shell=True).decode().split()[0])\n",
    "        val_count = int(subprocess.check_output(\"wc -l /content/data/val.jsonl\", shell=True).decode().split()[0])\n",
    "        \n",
    "        print(f\"\\n📈 데이터셋 크기:\")\n",
    "        print(f\"  - 학습 샘플: {train_count:,}개\")\n",
    "        print(f\"  - 검증 샘플: {val_count:,}개\")\n",
    "        \n",
    "        print(f\"\\n💡 용량 부족 시 Drive의 압축 파일을 삭제하세요:\")\n",
    "        print(f\"   !rm {tar_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️  샘플 수 확인 중 에러: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6118f1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔄 Colab 초기화 (압축 해제 실패 시)\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "print(\"🗑️  기존 데이터 삭제 중...\")\n",
    "\n",
    "# /content/data 삭제\n",
    "if os.path.exists('/content/data'):\n",
    "    shutil.rmtree('/content/data')\n",
    "    print(\"✅ /content/data 삭제 완료\")\n",
    "\n",
    "# 압축 파일 삭제 (Colab 로컬에 있다면)\n",
    "if os.path.exists('/content/korean_signboard_data.tar.gz'):\n",
    "    os.remove('/content/korean_signboard_data.tar.gz')\n",
    "    print(\"✅ 압축 파일 삭제 완료\")\n",
    "\n",
    "# 체크포인트 삭제 (있다면)\n",
    "if os.path.exists('/content/deepseek_ocr_korean_signboard'):\n",
    "    shutil.rmtree('/content/deepseek_ocr_korean_signboard')\n",
    "    print(\"✅ 체크포인트 삭제 완료\")\n",
    "\n",
    "print(\"\\n📊 현재 디스크 사용량:\")\n",
    "!df -h /content\n",
    "\n",
    "print(\"\\n✅ 초기화 완료! 아래 셀부터 다시 실행하세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d905e22a",
   "metadata": {},
   "source": [
    "### ⚠️ 압축 해제 실패 시 초기화\n",
    "\n",
    "**압축 해제가 실패했다면 아래 셀을 먼저 실행하세요:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79f9c00",
   "metadata": {},
   "source": [
    "## 3️⃣ DeepSeek-OCR 모델 로딩\n",
    "\n",
    "**🤖 여기서 하는 일:**\n",
    "- DeepSeek-OCR 3B 모델을 Hugging Face에서 다운로드\n",
    "- 4비트 양자화로 메모리 효율적 로딩 (8GB → 2GB)\n",
    "- 약 1-2분 소요\n",
    "\n",
    "**💡 Tip**: 처음 실행 시 모델 다운로드로 시간이 조금 걸립니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce3ccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastVisionModel\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "print(\"📥 DeepSeek-OCR 모델 다운로드 및 로딩 중...\")\n",
    "print(\"(처음 실행 시 모델 다운로드로 1-2분 소요될 수 있습니다)\\n\")\n",
    "\n",
    "# 최대 시퀀스 길이\n",
    "max_seq_length = 2048\n",
    "\n",
    "# 4비트 양자화로 모델 로드\n",
    "model, tokenizer = FastVisionModel.from_pretrained(\n",
    "    \"unsloth/DeepSeek-OCR\",\n",
    "    load_in_4bit=True,  # 메모리 절약: 8GB → 2GB\n",
    "    use_gradient_checkpointing=\"unsloth\",  # Unsloth 최적화\n",
    ")\n",
    "\n",
    "print(\"✅ 모델 로딩 완료!\")\n",
    "print(f\"📊 모델 정보:\")\n",
    "print(f\"  - 이름: DeepSeek-OCR\")\n",
    "print(f\"  - 파라미터: ~3B\")\n",
    "print(f\"  - 양자화: 4-bit\")\n",
    "print(f\"  - 최대 길이: {max_seq_length} 토큰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7fc6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA 적용\n",
    "print(\"🔧 LoRA 어댑터 설정 중...\")\n",
    "print(\"(Vision + Language 레이어 모두 파인튜닝)\\n\")\n",
    "\n",
    "model = FastVisionModel.get_peft_model(\n",
    "    model,\n",
    "    finetune_vision_layers=True,      # Vision 인코더 학습\n",
    "    finetune_language_layers=True,    # Language 모델 학습\n",
    "    finetune_attention_modules=True,  # Attention 레이어 학습\n",
    "    finetune_mlp_modules=True,        # MLP 레이어 학습\n",
    "    \n",
    "    r=16,              # LoRA rank (높을수록 표현력 증가)\n",
    "    lora_alpha=16,     # LoRA scaling\n",
    "    lora_dropout=0,    # Dropout 없음\n",
    "    bias=\"none\",\n",
    "    random_state=42,\n",
    "    use_rslora=False,\n",
    "    loftq_config=None,\n",
    ")\n",
    "\n",
    "# 학습 가능한 파라미터 확인\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(\"✅ LoRA 적용 완료!\")\n",
    "print(f\"\\n📊 파라미터 정보:\")\n",
    "print(f\"  - 전체 파라미터: {total_params:,}\")\n",
    "print(f\"  - 학습 파라미터: {trainable_params:,}\")\n",
    "print(f\"  - 학습 비율: {trainable_params/total_params*100:.2f}%\")\n",
    "print(f\"\\n💡 LoRA를 사용하면 전체의 {trainable_params/total_params*100:.2f}%만 학습하여 메모리와 시간을 절약합니다!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ec5fad",
   "metadata": {},
   "source": [
    "## 4️⃣ 데이터셋 로딩 및 확인\n",
    "\n",
    "**📊 데이터 형식:**\n",
    "- `train.jsonl`: 138,149개 학습 샘플\n",
    "- `val.jsonl`: 17,272개 검증 샘플\n",
    "- 각 샘플: 이미지 경로 + 대화 형식 (질문 → 답변)\n",
    "\n",
    "**✅ 여기서 확인할 것:**\n",
    "- 샘플 수가 정확한지 확인\n",
    "- 샘플 데이터 구조 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793bd189",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"📂 데이터셋 로딩 중...\\n\")\n",
    "\n",
    "# 데이터셋 로드\n",
    "train_dataset = load_dataset(\n",
    "    \"json\", \n",
    "    data_files=\"/content/data/train.jsonl\", \n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "val_dataset = load_dataset(\n",
    "    \"json\", \n",
    "    data_files=\"/content/data/val.jsonl\", \n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "print(\"✅ 데이터셋 로딩 완료!\")\n",
    "print(f\"\\n📊 데이터셋 크기:\")\n",
    "print(f\"  - 학습 샘플: {len(train_dataset):,}개\")\n",
    "print(f\"  - 검증 샘플: {len(val_dataset):,}개\")\n",
    "print(f\"  - 전체: {len(train_dataset) + len(val_dataset):,}개\")\n",
    "\n",
    "# 샘플 확인\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📄 샘플 데이터 구조 (첫 번째 샘플):\")\n",
    "print(\"=\"*60)\n",
    "sample = train_dataset[0]\n",
    "print(f\"이미지 경로: {sample['image']}\")\n",
    "print(f\"\\n질문: {sample['conversations'][0]['content']}\")\n",
    "print(f\"답변: {sample['conversations'][1]['content']}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n💡 A100 GPU 기준 예상 학습 시간: 2-3시간\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae017213",
   "metadata": {},
   "source": [
    "## 5️⃣ 트레이너 설정\n",
    "\n",
    "**⚙️ 학습 설정:**\n",
    "- **배치 크기**: 2 (per device)\n",
    "- **Gradient Accumulation**: 4 (효과적 배치 크기 = 8)\n",
    "- **학습 에폭**: 1회 전체 데이터\n",
    "- **학습률**: 2e-4\n",
    "- **최적화**: AdamW 8-bit\n",
    "\n",
    "**💾 저장 설정:**\n",
    "- 500 스텝마다 체크포인트 저장\n",
    "- 최대 3개 체크포인트 유지\n",
    "- 100 스텝마다 검증\n",
    "\n",
    "**⏱️ 예상 시간:**\n",
    "- Total Steps: ~17,268 (138,149 / 8)\n",
    "- A100 기준: **2-3시간**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605cafaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextStreamer\n",
    "from unsloth import is_bf16_supported\n",
    "from unsloth.trainer import UnslothVisionDataCollator\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "print(\"⚙️  트레이너 설정 중...\\n\")\n",
    "\n",
    "# 데이터 콜레이터\n",
    "data_collator = UnslothVisionDataCollator(model, tokenizer)\n",
    "\n",
    "# 학습 설정값\n",
    "batch_size = 2\n",
    "grad_accum = 4\n",
    "effective_batch_size = batch_size * grad_accum\n",
    "total_steps = len(train_dataset) // effective_batch_size\n",
    "\n",
    "print(f\"📊 학습 설정:\")\n",
    "print(f\"  - 배치 크기: {batch_size}\")\n",
    "print(f\"  - Gradient Accumulation: {grad_accum}\")\n",
    "print(f\"  - 효과적 배치 크기: {effective_batch_size}\")\n",
    "print(f\"  - 전체 스텝 수: {total_steps:,}\")\n",
    "print(f\"  - 학습 에폭: 1\")\n",
    "print(f\"  - 학습률: 2e-4\")\n",
    "print(f\"\\n⏱️  A100 GPU 기준 예상 시간: 2-3시간\")\n",
    "print(f\"\\n💡 중간에 중단되어도 체크포인트에서 재개 가능합니다!\")\n",
    "\n",
    "# 트레이너 설정\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    args=SFTConfig(\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        gradient_accumulation_steps=grad_accum,\n",
    "        \n",
    "        warmup_steps=100,\n",
    "        num_train_epochs=1,  # 1 에폭 (전체 데이터 1회)\n",
    "        # max_steps=100,  # 테스트용: 주석 해제하면 100 스텝만 학습\n",
    "        \n",
    "        learning_rate=2e-4,\n",
    "        fp16=not is_bf16_supported(),\n",
    "        bf16=is_bf16_supported(),\n",
    "        \n",
    "        logging_steps=25,      # 25 스텝마다 로그\n",
    "        eval_steps=500,        # 500 스텝마다 검증\n",
    "        save_steps=500,        # 500 스텝마다 저장\n",
    "        save_total_limit=3,    # 최대 3개 체크포인트\n",
    "        \n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.01,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        seed=42,\n",
    "        \n",
    "        output_dir=\"/content/deepseek_ocr_korean_signboard\",\n",
    "        report_to=\"none\",\n",
    "        \n",
    "        remove_unused_columns=False,\n",
    "        dataset_text_field=\"\",\n",
    "        dataset_kwargs={\"skip_prepare_dataset\": True},\n",
    "        dataset_num_proc=4,\n",
    "        max_seq_length=max_seq_length,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\"\\n✅ 트레이너 설정 완료!\")\n",
    "print(\"\\n🚀 다음 셀을 실행하면 학습이 시작됩니다!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98ff17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚀🚀🚀 학습 시작! 🚀🚀🚀\n",
    "import time\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"🚀 학습 시작!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n📊 학습 정보:\")\n",
    "print(f\"  - 학습 샘플: {len(train_dataset):,}개\")\n",
    "print(f\"  - 검증 샘플: {len(val_dataset):,}개\")\n",
    "print(f\"  - Effective Batch Size: {2 * 4} (batch_size × grad_accum)\")\n",
    "print(f\"  - Total Steps: {len(train_dataset) // (2 * 4):,}\")\n",
    "print(f\"\\n⏱️  예상 시간: 2-3시간 (A100 GPU)\")\n",
    "print(f\"\\n💡 팁:\")\n",
    "print(f\"  - 로그를 보면서 loss가 감소하는지 확인하세요\")\n",
    "print(f\"  - 500 스텝마다 자동으로 체크포인트가 저장됩니다\")\n",
    "print(f\"  - 중단되어도 체크포인트에서 재개 가능합니다\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"학습 시작...\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# 학습 실행\n",
    "trainer_stats = trainer.train()\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🎉 학습 완료!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n⏱️  총 소요 시간: {elapsed_time/3600:.2f}시간 ({elapsed_time/60:.1f}분)\")\n",
    "print(f\"📊 최종 Loss: {trainer_stats.training_loss:.4f}\")\n",
    "print(\"\\n✅ 다음 단계: 모델 저장 및 평가\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc7737b",
   "metadata": {},
   "source": [
    "## 6️⃣ 모델 저장\n",
    "\n",
    "**💾 저장 위치:**\n",
    "1. **Colab 로컬**: `/content/deepseek_ocr_korean_signboard/final`\n",
    "   - Colab 세션이 끝나면 삭제됨\n",
    "   \n",
    "2. **Google Drive**: `/content/drive/MyDrive/deepseek_ocr_finetuned`\n",
    "   - 영구 보관 (중요!)\n",
    "   - 나중에 로컬로 다운로드 가능\n",
    "\n",
    "**⚠️ 중요**: Google Drive 백업을 꼭 확인하세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a802b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"💾 모델 저장 중...\\n\")\n",
    "\n",
    "# 로컬 저장\n",
    "print(\"1️⃣ Colab 로컬에 저장 중...\")\n",
    "model.save_pretrained(\"/content/deepseek_ocr_korean_signboard/final\")\n",
    "tokenizer.save_pretrained(\"/content/deepseek_ocr_korean_signboard/final\")\n",
    "print(\"✅ 로컬 저장 완료: /content/deepseek_ocr_korean_signboard/final\")\n",
    "\n",
    "# Google Drive에 백업\n",
    "print(\"\\n2️⃣ Google Drive에 백업 중... (중요!)\")\n",
    "!cp -r /content/deepseek_ocr_korean_signboard/final /content/drive/MyDrive/deepseek_ocr_finetuned\n",
    "print(\"✅ Google Drive 백업 완료!\")\n",
    "\n",
    "# 저장된 파일 확인\n",
    "print(\"\\n📂 저장된 파일:\")\n",
    "!ls -lh /content/drive/MyDrive/deepseek_ocr_finetuned/\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✅ 모델 저장 완료!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n📍 저장 위치:\")\n",
    "print(\"  - Colab 로컬: /content/deepseek_ocr_korean_signboard/final\")\n",
    "print(\"  - Google Drive: 내 드라이브/deepseek_ocr_finetuned\")\n",
    "print(\"\\n💡 Google Drive에서 언제든지 다운로드 가능합니다!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951a3a86",
   "metadata": {},
   "source": [
    "## 7️⃣ 추론 테스트\n",
    "\n",
    "**🧪 여기서 하는 일:**\n",
    "- 학습된 모델로 실제 이미지 테스트\n",
    "- 간판 이미지 → 텍스트 추출\n",
    "\n",
    "**💡 다른 이미지로 테스트하려면:**\n",
    "- `test_image_path` 변수를 원하는 이미지 경로로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b13489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "print(\"🧪 추론 테스트 시작...\\n\")\n",
    "\n",
    "# 추론 모드로 전환\n",
    "FastVisionModel.for_inference(model)\n",
    "print(\"✅ 추론 모드로 전환 완료\")\n",
    "\n",
    "# 테스트 이미지 로드 (검증 데이터 첫 번째 이미지)\n",
    "sample = val_dataset[0]\n",
    "test_image_path = f\"/content/data/{sample['image']}\"\n",
    "ground_truth = sample['conversations'][1]['content']\n",
    "\n",
    "print(f\"\\n📸 테스트 이미지: {test_image_path}\")\n",
    "print(f\"📝 정답: {ground_truth}\")\n",
    "\n",
    "image = Image.open(test_image_path)\n",
    "\n",
    "# 프롬프트 구성\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"image\"},\n",
    "        {\"type\": \"text\", \"text\": \"이 간판 이미지의 텍스트를 읽어주세요.\"}\n",
    "    ]}\n",
    "]\n",
    "\n",
    "# 토큰화\n",
    "input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
    "inputs = tokenizer(\n",
    "    image,\n",
    "    input_text,\n",
    "    add_special_tokens=False,\n",
    "    return_tensors=\"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "# 생성\n",
    "print(\"\\n🤖 모델 예측:\")\n",
    "print(\"-\" * 40)\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "output = model.generate(\n",
    "    **inputs, \n",
    "    streamer=text_streamer, \n",
    "    max_new_tokens=128,\n",
    "    use_cache=True,\n",
    "    temperature=0.5,\n",
    "    min_p=0.1\n",
    ")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 결과 비교\n",
    "predicted_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(f\"\\n📊 결과 비교:\")\n",
    "print(f\"  정답: {ground_truth}\")\n",
    "print(f\"  예측: {predicted_text}\")\n",
    "print(f\"  일치: {'✅ 완전 일치!' if predicted_text.strip() == ground_truth.strip() else '❌ 불일치'}\")\n",
    "\n",
    "print(\"\\n✅ 추론 테스트 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92dcfb8",
   "metadata": {},
   "source": [
    "## 8️⃣ 전체 평가 (베이스라인과 비교)\n",
    "\n",
    "**📊 평가 방법:**\n",
    "- 검증 데이터 20개 샘플로 테스트\n",
    "- **완전 일치**: 대소문자/공백까지 정확히 일치\n",
    "- **정규화 일치**: 소문자 변환 + 공백 제거 후 일치\n",
    "\n",
    "**🎯 베이스라인 (학습 전) 성능:**\n",
    "- 완전 일치: 10%\n",
    "- 정규화 일치: 35%\n",
    "\n",
    "**✅ 파인튜닝 후 성능 향상 확인!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0716e9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "# 텍스트 정규화 함수\n",
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', '', text)\n",
    "    text = re.sub(r'[^가-힣a-z0-9]', '', text)\n",
    "    return text\n",
    "\n",
    "print(\"🔍 전체 평가 시작...\\n\")\n",
    "print(\"📊 20개 샘플로 평가 진행 중...\")\n",
    "\n",
    "# 평가 데이터 로드 (20개 샘플)\n",
    "eval_samples = val_dataset.select(range(20))\n",
    "\n",
    "correct = 0\n",
    "normalized_match = 0\n",
    "total = 0\n",
    "results = []\n",
    "\n",
    "for idx, sample in enumerate(tqdm(eval_samples, desc=\"평가 중\")):\n",
    "    try:\n",
    "        # 이미지 로드\n",
    "        image_path = f\"/content/data/{sample['image']}\"\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        # 정답\n",
    "        ground_truth = sample['conversations'][1]['content']\n",
    "        \n",
    "        # 예측\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"image\"},\n",
    "                {\"type\": \"text\", \"text\": sample['conversations'][0]['content']}\n",
    "            ]}\n",
    "        ]\n",
    "        \n",
    "        input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
    "        inputs = tokenizer(image, input_text, add_special_tokens=False, return_tensors=\"pt\").to(\"cuda\")\n",
    "        \n",
    "        output = model.generate(**inputs, max_new_tokens=128, use_cache=True, temperature=0.5)\n",
    "        prediction = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        \n",
    "        # 정확도 계산\n",
    "        exact_match = prediction.strip() == ground_truth.strip()\n",
    "        norm_match = normalize_text(prediction) == normalize_text(ground_truth)\n",
    "        \n",
    "        if exact_match:\n",
    "            correct += 1\n",
    "        \n",
    "        if norm_match:\n",
    "            normalized_match += 1\n",
    "        \n",
    "        total += 1\n",
    "        \n",
    "        # 결과 저장\n",
    "        results.append({\n",
    "            \"image\": sample['image'],\n",
    "            \"ground_truth\": ground_truth,\n",
    "            \"prediction\": prediction,\n",
    "            \"exact_match\": exact_match,\n",
    "            \"normalized_match\": norm_match\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"에러 (샘플 {idx}): {e}\")\n",
    "        continue\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📊 평가 결과\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n✅ 파인튜닝 후 성능:\")\n",
    "print(f\"  - 완전 일치: {correct/total*100:.2f}% ({correct}/{total})\")\n",
    "print(f\"  - 정규화 일치: {normalized_match/total*100:.2f}% ({normalized_match}/{total})\")\n",
    "\n",
    "print(f\"\\n📉 베이스라인 (학습 전) 성능:\")\n",
    "print(f\"  - 완전 일치: 10.00% (2/20)\")\n",
    "print(f\"  - 정규화 일치: 35.00% (7/20)\")\n",
    "\n",
    "print(f\"\\n📈 성능 향상:\")\n",
    "print(f\"  - 완전 일치: {(correct/total*100 - 10):.2f}% 포인트 증가\")\n",
    "print(f\"  - 정규화 일치: {(normalized_match/total*100 - 35):.2f}% 포인트 증가\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 틀린 예시 몇 개 출력\n",
    "print(\"\\n❌ 불일치 샘플 예시:\")\n",
    "wrong_samples = [r for r in results if not r['exact_match']][:3]\n",
    "for i, sample in enumerate(wrong_samples, 1):\n",
    "    print(f\"\\n{i}. {sample['image']}\")\n",
    "    print(f\"   정답: {sample['ground_truth']}\")\n",
    "    print(f\"   예측: {sample['prediction']}\")\n",
    "\n",
    "print(\"\\n✅ 평가 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36d3dd8",
   "metadata": {},
   "source": [
    "## 9️⃣ 완료 및 다음 단계\n",
    "\n",
    "**🎉 축하합니다! 모든 과정이 완료되었습니다!**\n",
    "\n",
    "---\n",
    "\n",
    "## 📦 저장된 파일 위치:\n",
    "\n",
    "### Google Drive (영구 보관):\n",
    "```\n",
    "내 드라이브/deepseek_ocr_finetuned/\n",
    "  ├── adapter_config.json\n",
    "  ├── adapter_model.safetensors\n",
    "  ├── tokenizer_config.json\n",
    "  └── ... (기타 파일들)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 💻 로컬에서 사용하는 방법:\n",
    "\n",
    "### 1. Google Drive에서 다운로드\n",
    "- Google Drive에 접속\n",
    "- `deepseek_ocr_finetuned` 폴더를 로컬로 다운로드\n",
    "\n",
    "### 2. 추론 코드 (WSL에서 실행)\n",
    "```python\n",
    "from unsloth import FastVisionModel\n",
    "from PIL import Image\n",
    "\n",
    "# 모델 로드\n",
    "model, tokenizer = FastVisionModel.from_pretrained(\n",
    "    \"/path/to/deepseek_ocr_finetuned\",  # 다운로드한 경로\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "FastVisionModel.for_inference(model)\n",
    "\n",
    "# 추론\n",
    "image = Image.open(\"signboard.jpg\")\n",
    "messages = [{\"role\": \"user\", \"content\": [\n",
    "    {\"type\": \"image\"},\n",
    "    {\"type\": \"text\", \"text\": \"이 간판 이미지의 텍스트를 읽어주세요.\"}\n",
    "]}]\n",
    "\n",
    "input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
    "inputs = tokenizer(image, input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "output = model.generate(**inputs, max_new_tokens=128)\n",
    "result = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🚀 선택사항:\n",
    "\n",
    "### HuggingFace Hub에 업로드 (아래 셀 실행):\n",
    "- 다른 사람과 공유하거나 API로 사용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16145b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎉 모든 작업 완료!\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📂 파일 저장 위치\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n✅ Google Drive (영구 보관):\")\n",
    "print(\"   📍 내 드라이브/deepseek_ocr_finetuned/\")\n",
    "print(\"\\n✅ Colab 로컬 (세션 종료 시 삭제됨):\")\n",
    "print(\"   📍 /content/deepseek_ocr_korean_signboard/final/\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📊 최종 성능 요약\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n베이스라인 → 파인튜닝 후:\")\n",
    "print(f\"  완전 일치: 10% → ??%\")\n",
    "print(f\"  정규화 일치: 35% → ??%\")\n",
    "print(f\"\\n💡 위 평가 결과를 참고하세요!\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🚀 다음 단계\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n1️⃣ Google Drive에서 모델 다운로드\")\n",
    "print(\"2️⃣ 로컬(WSL)에서 추론 테스트\")\n",
    "print(\"3️⃣ 실제 서비스에 적용\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# HuggingFace Hub 업로드 (선택사항)\n",
    "print(\"\\n💡 HuggingFace Hub에 업로드하려면:\")\n",
    "print(\"   1. HuggingFace 토큰 준비\")\n",
    "print(\"   2. 아래 코드 주석 해제 후 실행\")\n",
    "print(\"\\n\")\n",
    "print(\"# from huggingface_hub import login\")\n",
    "print(\"# login(token='your_token_here')\")\n",
    "print(\"# model.push_to_hub('your-username/deepseek-ocr-korean-signboard')\")\n",
    "print(\"# tokenizer.push_to_hub('your-username/deepseek-ocr-korean-signboard')\")\n",
    "\n",
    "print(\"\\n\\n🎊 축하합니다! 한국어 간판 OCR 모델 파인튜닝 완료! 🎊\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
