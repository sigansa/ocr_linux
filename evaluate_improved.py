#!/usr/bin/env python3
"""
Qwen2-VL ê°œì„ ëœ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
ì •ê·œí™” + ìœ ì‚¬ë„ ê¸°ë°˜ í‰ê°€
"""

import torch
from transformers import Qwen2VLForConditionalGeneration, AutoProcessor
from PIL import Image
import json
from tqdm import tqdm
import re
from difflib import SequenceMatcher

print("ğŸ“¦ ëª¨ë¸ ë¡œë”© ì¤‘...")
model = Qwen2VLForConditionalGeneration.from_pretrained(
    "Qwen/Qwen2-VL-2B-Instruct",
    torch_dtype=torch.bfloat16,
    device_map="auto",
    trust_remote_code=True,
)

processor = AutoProcessor.from_pretrained("Qwen/Qwen2-VL-2B-Instruct")
print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ\n")

# í…ìŠ¤íŠ¸ ì •ê·œí™” í•¨ìˆ˜
def normalize_text(text):
    """í…ìŠ¤íŠ¸ ì •ê·œí™”: ì†Œë¬¸ì, ê³µë°± ì œê±°, íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬"""
    # ì†Œë¬¸ì ë³€í™˜
    text = text.lower()
    # ê³µë°± ì œê±°
    text = re.sub(r'\s+', '', text)
    # íŠ¹ìˆ˜ë¬¸ì ì œê±° (í•œê¸€, ì˜ë¬¸, ìˆ«ìë§Œ ë‚¨ê¹€)
    text = re.sub(r'[^ê°€-í£a-z0-9]', '', text)
    return text

# ìœ ì‚¬ë„ ê³„ì‚°
def calculate_similarity(text1, text2):
    """ë‘ í…ìŠ¤íŠ¸ì˜ ìœ ì‚¬ë„ ê³„ì‚° (0~1)"""
    return SequenceMatcher(None, text1, text2).ratio()

# ê°„ë‹¨í•œ í›„ì²˜ë¦¬
def postprocess_prediction(pred_text):
    """ë¶ˆí•„ìš”í•œ ì •ë³´ ì œê±°"""
    # ì¤„ë°”ê¿ˆìœ¼ë¡œ ë¶„ë¦¬ëœ ê²½ìš° ì²« ì¤„ë§Œ
    pred_text = pred_text.split('\n')[0].strip()
    
    # "The text on the sign..." ê°™ì€ ì„¤ëª… ì œê±°
    if 'text' in pred_text.lower() and ('sign' in pred_text.lower() or 'image' in pred_text.lower()):
        # ë§ˆì§€ë§‰ ë”°ì˜´í‘œ ì•ˆì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„
        if '"' in pred_text:
            parts = pred_text.split('"')
            if len(parts) >= 2:
                pred_text = parts[-2]
    
    return pred_text.strip()

# í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
print("ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”© ì¤‘...")
with open("/root/data/deepseek_ocr/val_qwen2vl.jsonl", 'r', encoding='utf-8') as f:
    test_data = [json.loads(line) for line in f]

test_samples = test_data[:20]
print(f"í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ: {len(test_samples)}ê°œ\n")

# í‰ê°€
print("ğŸ” ê°œì„ ëœ í‰ê°€ ì‹œì‘...")
print("="*80)

exact_match = 0
normalized_match = 0
high_similarity = 0  # ìœ ì‚¬ë„ 80% ì´ìƒ
total = 0
results = []

for idx, item in enumerate(tqdm(test_samples, desc="í‰ê°€ ì¤‘")):
    messages = item["messages"]
    
    # ì •ë‹µ ì¶”ì¶œ
    image_path = messages[0]["content"][0]["image"]
    user_text = messages[0]["content"][1]["text"]
    ground_truth = messages[1]["content"][0]["text"]
    
    # ì´ë¯¸ì§€ ë¡œë“œ
    try:
        image = Image.open(image_path).convert("RGB")
    except Exception as e:
        print(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}")
        continue
    
    # ëŒ€í™” êµ¬ì„±
    conversation = [
        {
            "role": "user",
            "content": [
                {"type": "image"},
                {"type": "text", "text": user_text}
            ]
        }
    ]
    
    # ì¶”ë¡ 
    text_prompt = processor.apply_chat_template(conversation, add_generation_prompt=True, tokenize=False)
    inputs = processor(
        text=[text_prompt],
        images=[image],
        padding=True,
        return_tensors="pt"
    ).to("cuda")
    
    with torch.no_grad():
        output_ids = model.generate(
            **inputs,
            max_new_tokens=128,
            do_sample=False,
        )
    
    generated_text = processor.batch_decode(output_ids, skip_special_tokens=True)[0]
    
    # ì‘ë‹µ ì¶”ì¶œ
    if "assistant\n" in generated_text:
        prediction = generated_text.split("assistant\n")[-1].strip()
    else:
        prediction = generated_text.split("assistant")[-1].strip() if "assistant" in generated_text else generated_text
    
    # í›„ì²˜ë¦¬
    prediction_clean = postprocess_prediction(prediction)
    
    # ì •ê·œí™”
    gt_norm = normalize_text(ground_truth)
    pred_norm = normalize_text(prediction_clean)
    
    # ìœ ì‚¬ë„ ê³„ì‚°
    similarity = calculate_similarity(gt_norm, pred_norm)
    
    # ì •í™•ë„ ì²´í¬
    is_exact = prediction_clean.strip() == ground_truth.strip()
    is_normalized = gt_norm == pred_norm
    is_similar = similarity >= 0.8
    
    if is_exact:
        exact_match += 1
    if is_normalized:
        normalized_match += 1
    if is_similar:
        high_similarity += 1
    
    total += 1
    
    results.append({
        "index": idx + 1,
        "ground_truth": ground_truth,
        "prediction_raw": prediction,
        "prediction_clean": prediction_clean,
        "gt_normalized": gt_norm,
        "pred_normalized": pred_norm,
        "similarity": similarity,
        "exact_match": is_exact,
        "normalized_match": is_normalized,
        "high_similarity": is_similar
    })

# ê²°ê³¼ ì¶œë ¥
print("\n" + "="*80)
print("ğŸ“Š í‰ê°€ ê²°ê³¼")
print("="*80)
print(f"ì´ ìƒ˜í”Œ: {total}ê°œ\n")

print("1ï¸âƒ£ ì™„ì „ ì¼ì¹˜ (ì›ë³¸ ê·¸ëŒ€ë¡œ):")
print(f"   ì •í™•ë„: {exact_match/total*100:.2f}% ({exact_match}/{total})")

print("\n2ï¸âƒ£ ì •ê·œí™” ì¼ì¹˜ (ì†Œë¬¸ì+ê³µë°±ì œê±°):")
print(f"   ì •í™•ë„: {normalized_match/total*100:.2f}% ({normalized_match}/{total})")

print("\n3ï¸âƒ£ ê³ ìœ ì‚¬ë„ (80% ì´ìƒ):")
print(f"   ì •í™•ë„: {high_similarity/total*100:.2f}% ({high_similarity}/{total})")

print("="*80)

# ìƒ˜í”Œ ê²°ê³¼ ì¶œë ¥
print("\nğŸ“ ìƒì„¸ ê²°ê³¼ (ì²˜ìŒ 10ê°œ):")
print("-"*80)
for result in results[:10]:
    print(f"\nìƒ˜í”Œ {result['index']}:")
    print(f"  ì •ë‹µ: {result['ground_truth']}")
    print(f"  ì˜ˆì¸¡: {result['prediction_clean']}")
    print(f"  ìœ ì‚¬ë„: {result['similarity']*100:.1f}%")
    
    status = []
    if result['exact_match']:
        status.append("âœ… ì™„ì „ì¼ì¹˜")
    if result['normalized_match']:
        status.append("âœ… ì •ê·œí™”ì¼ì¹˜")
    if result['high_similarity']:
        status.append("âœ… ê³ ìœ ì‚¬ë„")
    
    if not status:
        status.append("âŒ ë¶ˆì¼ì¹˜")
    
    print(f"  ìƒíƒœ: {' '.join(status)}")

# ê²°ê³¼ ì €ì¥
output_file = "/root/data/qwen2vl_improved_eval.json"
with open(output_file, 'w', encoding='utf-8') as f:
    json.dump({
        "total": total,
        "exact_match": exact_match,
        "normalized_match": normalized_match,
        "high_similarity": high_similarity,
        "accuracy": {
            "exact": exact_match/total*100,
            "normalized": normalized_match/total*100,
            "similarity_80": high_similarity/total*100
        },
        "results": results
    }, f, ensure_ascii=False, indent=2)

print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_file}")
print("\nâœ… ê°œì„ ëœ í‰ê°€ ì™„ë£Œ!")
